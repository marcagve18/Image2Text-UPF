{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YchvOluYaQW2",
        "outputId": "4482b4b0-b0a9-485e-e37d-b01c817ce559"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/andreu/Documents/Bachelors Degree In Computer Engineering/ThirdYear/ThirdTrimester/Deep Learning/Practices/Image2Text-UPF/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from pycocotools.coco import COCO\n",
        "import os\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from PIL import Image\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline, set_seed\n",
        "\n",
        "\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../data/instances_val2014.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m data_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mval2014\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m instances_ann_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstances_\u001b[39m\u001b[39m{\u001b[39;00mdata_type\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m coco \u001b[39m=\u001b[39m COCO(instances_ann_file)\n\u001b[1;32m      8\u001b[0m \u001b[39m# initialize COCO API for caption annotations\u001b[39;00m\n\u001b[1;32m      9\u001b[0m captions_ann_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_dir,  \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcaptions_\u001b[39m\u001b[39m{\u001b[39;00mdata_type\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Documents/Bachelors Degree In Computer Engineering/ThirdYear/ThirdTrimester/Deep Learning/Practices/Image2Text-UPF/.venv/lib/python3.11/site-packages/pycocotools/coco.py:81\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloading annotations into memory...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m tic \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 81\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(annotation_file, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     82\u001b[0m     dataset \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     83\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mtype\u001b[39m(dataset)\u001b[39m==\u001b[39m\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mannotation file format \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m not supported\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(dataset))\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/instances_val2014.json'"
          ]
        }
      ],
      "source": [
        "data_dir = \"../data/\"\n",
        "# data_dir = \"/content/drive/MyDrive/Colab Notebooks/test/\"\n",
        "data_type = \"val2014\"\n",
        "instances_ann_file = os.path.join(data_dir, f\"instances_{data_type}.json\")\n",
        "\n",
        "\n",
        "coco = COCO(instances_ann_file)\n",
        "# initialize COCO API for caption annotations\n",
        "captions_ann_file = os.path.join(data_dir,  f\"captions_{data_type}.json\")\n",
        "coco_caps = COCO(captions_ann_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "S6iNezAuY_UM",
        "outputId": "3aba920f-39aa-49c4-9452-b68239407b39"
      },
      "outputs": [],
      "source": [
        "\n",
        "# get image ids\n",
        "ids = list(coco.anns.keys())\n",
        "\n",
        "# pick a random image and obtain the corresponding URL\n",
        "ann_id = np.random.choice(ids)\n",
        "img_id = coco.anns[ann_id][\"image_id\"]\n",
        "img = coco.loadImgs(img_id)[0]\n",
        "url = img[\"coco_url\"]\n",
        "\n",
        "print(img)\n",
        "# print URL and visualize corresponding image\n",
        "print(url)\n",
        "I = io.imread(url)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(I)\n",
        "\n",
        "# load and display captions\n",
        "ann_ids = coco_caps.getAnnIds(imgIds=img[\"id\"])\n",
        "anns = coco_caps.loadAnns(ann_ids)\n",
        "coco_caps.showAnns(anns)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpSBJEhchla3",
        "outputId": "dafe6eb8-a94b-41d4-d9b3-15db38857bc5"
      },
      "outputs": [],
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "input_tensor = preprocess(Image.fromarray(I))\n",
        "input_batch = input_tensor.unsqueeze(0)\n",
        "model.classifier[6] = nn.Linear(in_features=4096, out_features=384, bias=True)\n",
        "print(model)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4bo01XPiGBP",
        "outputId": "a1e8ddf1-2767-43ea-a04e-5afe8a587d4a"
      },
      "outputs": [],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIELGOMwipVD",
        "outputId": "ceb88d37-e597-4199-8c27-75a8b61047f6"
      },
      "outputs": [],
      "source": [
        "model_name = 'gpt2'  # or 'gpt2-medium', 'gpt2-large', etc.\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "input_text = \"Hello my name is\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "print(input_ids)\n",
        "output = model.generate(input_ids)\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQu4krhCk8LL",
        "outputId": "fcf03450-c3e9-4a71-b687-46dce3e7f884"
      },
      "outputs": [],
      "source": [
        "print(generated_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9CB-Q4spXUX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
